from dataclasses import dataclass
from pathlib import Path
from typing import Iterable, Optional
import joblib

from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder, StandardScaler
from imblearn.over_sampling import SMOTE


@dataclass
class PreprocessingData:
    """Data paths generated by PreprocessingStep.
    Regarding if it's the training or inference pipeline, the correct paths need to be implemented
    (respectively train_path, test_path / batch_path)
    """

    train_path: Optional[Path] = None
    test_path: Optional[Path] = None
    batch_path: Optional[Path] = None


@dataclass
class FeaturesEngineeringData:
    """Data and encoders paths generated by FeatureEngineeringStep.
    Regarding if it's the training or inference pipeline, the correct paths need to be implemented
    (respectively train_path, test_path / batch_path)"""

    encoders_path: Path
    train_path: Optional[Path] = None
    test_path: Optional[Path] = None
    batch_path: Optional[Path] = None


@dataclass
class FeaturesEncoder:
    """Encoders artifact dumped and loaded during the feature_engineering step."""
    resampler: SMOTE
    ordinal_encoder: OrdinalEncoder
    onehot_encoder: OneHotEncoder
    lb_encoder: LabelEncoder
    scaler: StandardScaler
    base_features: Iterable[str]
    ordinal_features: Iterable[str]
    onehot_features: Iterable[str]
    created_onehot_features: Iterable[str] # this attribute store onehot features created when OneHotEncoder fit to train data
    base_ordinal_onehot_columns: Iterable[str] # equal to base_features + ordinal_features + created_onehot_features
    target: str

    def to_joblib(self, path: Path) -> None:
        """Dump artifact as a joblib file.

        Args:
            path (Path): Encoders path
        """
        joblib.dump(self, path)
